# RelatÃ³rio do Projeto - Stock Prediction LSTM API

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um sistema completo de **ML Engineering** para previsÃ£o de preÃ§os de aÃ§Ãµes usando LSTM (Long Short-Term Memory), com foco em boas prÃ¡ticas de engenharia, monitoramento, versionamento e qualidade de cÃ³digo.

---

## ğŸ—ï¸ Arquitetura do Sistema

### **Componentes Principais**

```
stock-prediction-lstm-api/
â”œâ”€â”€ src/ml/                      # Core ML components
â”‚   â”œâ”€â”€ data/                    # Data pipeline
â”‚   â”‚   â”œâ”€â”€ ingestion.py         # Yahoo Finance integration
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py  # Technical indicators
â”‚   â”‚   â””â”€â”€ preprocessing.py     # Normalization & sequences
â”‚   â”œâ”€â”€ models/                  # Neural network models
â”‚   â”‚   â””â”€â”€ lstm.py              # PyTorch LSTM implementation
â”‚   â”œâ”€â”€ training/                # Training infrastructure
â”‚   â”‚   â”œâ”€â”€ trainer.py           # Training loop & checkpoints
â”‚   â”‚   â”œâ”€â”€ early_stopping.py    # Early stopping callback
â”‚   â”‚   â”œâ”€â”€ metrics.py           # Evaluation metrics
â”‚   â”‚   â”œâ”€â”€ hyperparameter_tuner.py  # Optuna integration
â”‚   â”‚   â””â”€â”€ experiment_tracker.py    # MLflow tracking
â”‚   â”œâ”€â”€ pipeline/                # End-to-end pipelines
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py    # Training orchestration
â”‚   â”‚   â””â”€â”€ predict_pipeline.py  # Prediction workflow
â”‚   â”œâ”€â”€ monitoring/              # Production monitoring
â”‚   â”‚   â””â”€â”€ drift_detector.py    # Data/concept drift detection
â”‚   â””â”€â”€ utils/                   # Utilities
â”‚       â”œâ”€â”€ persistence.py       # Data versioning & artifacts
â”‚       â”œâ”€â”€ device.py            # CPU/GPU management
â”‚       â”œâ”€â”€ logging.py           # Structured logging
â”‚       â””â”€â”€ seed.py              # Reproducibility
â”œâ”€â”€ cli/                         # Command-line interface
â”‚   â””â”€â”€ main.py                  # 5 CLI commands
â”œâ”€â”€ tests/                       # Comprehensive test suite
â”‚   â”œâ”€â”€ integration/             # Integration tests
â”‚   â”œâ”€â”€ unit/                    # Unit tests
â”‚   â””â”€â”€ test_*.py                # Test modules
â””â”€â”€ docs/                        # Documentation
```

---

## ğŸ¯ Funcionalidades Implementadas

### **1. Pipeline de Dados**
- âœ… **IngestÃ£o**: Download automÃ¡tico de dados do Yahoo Finance
- âœ… **Feature Engineering**: 14 indicadores tÃ©cnicos (SMA, EMA, RSI, MACD, Bollinger Bands, ATR)
- âœ… **Preprocessing**: NormalizaÃ§Ã£o MinMaxScaler, criaÃ§Ã£o de sequÃªncias temporais
- âœ… **ValidaÃ§Ã£o**: VerificaÃ§Ã£o de qualidade dos dados

### **2. Modelo LSTM**
- âœ… **Arquitetura**: PyTorch LSTM multi-camadas com dropout
- âœ… **Flexibilidade**: ConfigurÃ¡vel (hidden_size, num_layers, dropout, lookback)
- âœ… **Checkpoint**: Salvamento completo com arquitetura e pesos

### **3. Treinamento**
- âœ… **Trainer**: Loop de treinamento com validaÃ§Ã£o e logging
- âœ… **Early Stopping**: Previne overfitting com patience configurÃ¡vel
- âœ… **MLflow**: Rastreamento de experimentos, mÃ©tricas e modelos
- âœ… **OtimizaÃ§Ã£o**: Optuna para hyperparameter tuning
- âœ… **MÃ©tricas**: MAE, RMSE, MAPE, RÂ², Directional Accuracy

### **4. Pipelines Orquestrados**

#### **TrainPipeline** (5 etapas)
```python
1. Data Ingestion      â†’ Download from Yahoo Finance
2. Feature Engineering â†’ Add technical indicators
3. Preprocessing       â†’ Normalize & create sequences
4. Training           â†’ Train LSTM with validation
5. Evaluation         â†’ Calculate test metrics
```

#### **PredictPipeline** (4 etapas)
```python
1. Data Ingestion      â†’ Download latest 2 years
2. Feature Engineering â†’ Add indicators
3. Preprocessing       â†’ Prepare last sequence
4. Prediction         â†’ Multi-step forecasting
```

### **5. Monitoramento & Versionamento**
- âœ… **Drift Detection**: KS-test e PSI para detectar drift
- âœ… **Data Versioning**: Controle de versÃµes de datasets
- âœ… **Artifact Management**: Salvamento de scalers, configs, modelos
- âœ… **Auto Cleanup**: Limpeza automÃ¡tica de versÃµes antigas

### **6. Interface CLI**
```bash
# 5 comandos disponÃ­veis:
stock-predict train      # Treinar modelo
stock-predict predict    # Fazer previsÃµes
stock-predict tune       # Otimizar hiperparÃ¢metros
stock-predict drift      # Detectar drift
stock-predict pipeline   # Executar pipeline completo
```

### **7. Qualidade & Testes**
- âœ… **Ruff**: Linter/formatter Ãºnico (substitui black+isort+flake8+mypy)
- âœ… **83 testes**: 100% passando
- âœ… **Coverage**: 72.79%
- âœ… **Testes End-to-End**: Treino, retreino, prediÃ§Ã£o
- âœ… **Testes de IntegraÃ§Ã£o**: 8 testes
- âœ… **Testes UnitÃ¡rios**: 75+ testes

---

## ğŸ”Œ IntegraÃ§Ã£o com API REST

### **Arquitetura Proposta**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚
â”‚   (React/Vue)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flask         â”‚  â† API REST Layer
â”‚   + Pydantic    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ML Pipelines   â”‚  â† Existing Code
â”‚  (TrainPipeline)â”‚
â”‚  (PredictPipeline)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **ImplementaÃ§Ã£o Recomendada**

#### **1. Estrutura de DiretÃ³rios**
```
stock-prediction-lstm-api/
â”œâ”€â”€ api/                         # NEW: API layer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # FastAPI app
â”‚   â”œâ”€â”€ routers/                 # API endpoints
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â”œâ”€â”€ monitoring.py
â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”œâ”€â”€ schemas/                 # Pydantic models
â”‚   â”‚   â”œâ”€â”€ train_request.py
â”‚   â”‚   â”œâ”€â”€ predict_request.py
â”‚   â”‚   â””â”€â”€ responses.py
â”‚   â”œâ”€â”€ dependencies.py          # Dependency injection
â”‚   â””â”€â”€ background_tasks.py      # Async training
â””â”€â”€ src/ml/                      # Existing ML code
```

#### **2. Endpoints Principais**

```python
# api/routers/train.py
@router.post("/train", response_model=TrainResponse)
async def train_model(
    request: TrainRequest,
    background_tasks: BackgroundTasks
):
    """
    POST /api/v1/train
    {
        "ticker": "PETR4.SA",
        "start_date": "2023-01-01",
        "end_date": "2024-01-01",
        "lookback": 60,
        "hidden_size": 64,
        "epochs": 50
    }
    """
    task_id = str(uuid.uuid4())
    background_tasks.add_task(
        run_training_pipeline,
        task_id=task_id,
        params=request
    )
    return {"task_id": task_id, "status": "queued"}

# api/routers/predict.py
@router.post("/predict", response_model=PredictResponse)
async def predict_prices(request: PredictRequest):
    """
    POST /api/v1/predict
    {
        "ticker": "PETR4.SA",
        "model_path": "models/best_model.pt",
        "days_ahead": 5
    }
    """
    pipeline = PredictPipeline(
        model_path=request.model_path,
        ticker=request.ticker,
        lookback=request.lookback
    )
    predictions = pipeline.predict(days_ahead=request.days_ahead)
    
    return {
        "ticker": request.ticker,
        "predictions": predictions.to_dict(orient="records"),
        "generated_at": datetime.now().isoformat()
    }

# api/routers/monitoring.py
@router.post("/drift/detect")
async def detect_drift(request: DriftRequest):
    """
    POST /api/v1/drift/detect
    {
        "ticker": "PETR4.SA",
        "reference_version": "20240101_120000",
        "production_version": "20240201_120000"
    }
    """
    detector = DriftDetector()
    ref_data = load_data_version(request.reference_version)
    prod_data = load_data_version(request.production_version)
    
    report = detector.detect_drift(ref_data, prod_data)
    
    return {
        "has_drift": report["has_drift"],
        "drifted_features": report["drifted_features"],
        "drift_scores": report["drift_scores"],
        "recommendation": "retrain" if report["has_drift"] else "ok"
    }

# api/routers/health.py
@router.get("/health")
async def health_check():
    """GET /api/v1/health"""
    return {
        "status": "healthy",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat()
    }
```

#### **3. Schemas Pydantic**

```python
# api/schemas/train_request.py
class TrainRequest(BaseModel):
    ticker: str = Field(..., example="PETR4.SA")
    start_date: str = Field(..., example="2023-01-01")
    end_date: str = Field(..., example="2024-01-01")
    lookback: int = Field(60, ge=5, le=200)
    hidden_size: int = Field(64, ge=16, le=512)
    num_layers: int = Field(2, ge=1, le=5)
    epochs: int = Field(50, ge=1, le=1000)
    learning_rate: float = Field(0.001, gt=0, lt=1)
    
    class Config:
        schema_extra = {
            "example": {
                "ticker": "PETR4.SA",
                "start_date": "2023-01-01",
                "end_date": "2024-01-01",
                "lookback": 60,
                "hidden_size": 64,
                "epochs": 50
            }
        }

# api/schemas/predict_request.py
class PredictRequest(BaseModel):
    ticker: str
    model_path: str
    lookback: int = 60
    days_ahead: int = Field(5, ge=1, le=30)

# api/schemas/responses.py
class TrainResponse(BaseModel):
    task_id: str
    status: str
    message: str = "Training started"

class PredictResponse(BaseModel):
    ticker: str
    predictions: List[Dict[str, Any]]
    generated_at: str
    model_version: Optional[str]
```
 
 

## ğŸ“ Tecnologias Utilizadas

| Categoria | Tecnologia | VersÃ£o |
|-----------|-----------|--------|
| **ML Framework** | PyTorch | 2.1+ |
| **Data** | pandas, numpy | latest |
| **Tracking** | MLflow | 2.9+ |
| **Tuning** | Optuna | 3.5+ |
| **Testing** | pytest, pytest-cov | 8.0+, 7.0+ |
| **Quality** | Ruff | 0.1+ |
| **CLI** | Click | 8.1+ |
| **Logging** | Loguru | 0.7+ |

---
  