# ðŸš€ Guia de Deploy - Stock Prediction LSTM API

Este documento fornece instruÃ§Ãµes detalhadas para fazer deploy da API em diferentes plataformas de hosting.

---

## ðŸ“‹ Requisitos

- Python 3.11+
- PyTorch 2.2.2 (CPU-only)
- NumPy < 2.0
- Flask 3.1+
- Docker (opcional)
- 2.5GB de espaÃ§o em disco (para imagem Docker)
- 512MB RAM mÃ­nimo (recomendado: 1GB)

---

## ðŸ³ Deploy com Docker (Recomendado)

### **OpÃ§Ã£o 1: Docker Local**

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/adriannylelis/stock-prediction-lstm-api.git
cd stock-prediction-lstm-api

# 2. Build da imagem
docker build -t stock-prediction-api:latest .

# 3. Rodar container
docker run -d \
  --name stock-api \
  -p 5001:5001 \
  --restart unless-stopped \
  stock-prediction-api:latest

# 4. Verificar logs
docker logs -f stock-api

# 5. Testar API
curl http://localhost:5001/health
```

### **OpÃ§Ã£o 2: Docker Compose**

Crie um arquivo `docker-compose.yml`:

```yaml
version: '3.8'

services:
  api:
    image: stock-prediction-api:latest
    build: .
    container_name: stock-api
    ports:
      - "5001:5001"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
```

Comandos:
```bash
# Build e run
docker-compose up -d

# Ver logs
docker-compose logs -f

# Parar
docker-compose down
```

---

## â˜ï¸ Deploy em Cloud Providers

### **1. Render.com (Recomendado para Docker)**

**CaracterÃ­sticas:**
- âœ… Free tier disponÃ­vel
- âœ… Deploy automÃ¡tico via GitHub
- âœ… Suporte nativo a Docker
- âœ… SSL/HTTPS automÃ¡tico

**Passos:**

1. **Criar conta** em [render.com](https://render.com)

2. **Novo Web Service:**
   - Click em "New +" â†’ "Web Service"
   - Connect ao seu repositÃ³rio GitHub
   - Configure:
     ```
     Name: stock-prediction-api
     Environment: Docker
     Branch: main (ou dev-adri)
     ```

3. **ConfiguraÃ§Ãµes avanÃ§adas:**
   ```
   Docker Command: (deixar vazio - usa CMD do Dockerfile)
   Port: 5001
   Health Check Path: /health
   ```

4. **Deploy:**
   - Click em "Create Web Service"
   - Aguardar build (~10 minutos na primeira vez)
   - URL serÃ¡: https://stock-prediction-api.onrender.com

**LimitaÃ§Ãµes do Free Tier:**
- Container dorme apÃ³s 15 minutos de inatividade
- Primeiro request pode levar 30-60s (cold start)
- 750 horas/mÃªs grÃ¡tis

---

### **2. Railway.app**

**CaracterÃ­sticas:**
- âœ… $5 de crÃ©dito grÃ¡tis por mÃªs
- âœ… Deploy super rÃ¡pido
- âœ… Auto-scaling
- âœ… Suporte a Docker

**Passos:**

1. **Criar conta** em [railway.app](https://railway.app)

2. **Novo Projeto:**
   - Click em "New Project"
   - Selecione "Deploy from GitHub repo"
   - Escolha seu repositÃ³rio

3. **ConfiguraÃ§Ãµes:**
   - Railway detecta automaticamente o Dockerfile
   - VariÃ¡veis de ambiente: (nenhuma necessÃ¡ria)
   - Port: 5001 (detectado automaticamente)

4. **Deploy:**
   - Deploy automÃ¡tico a cada push no GitHub
   - URL gerada automaticamente
   - Logs em tempo real

**Custo:**
- $5 de crÃ©dito grÃ¡tis/mÃªs
- ~$0.01/hora depois do crÃ©dito

---

### **3. Fly.io**

**CaracterÃ­sticas:**
- âœ… Free tier com 3 VMs
- âœ… Deploy global (CDN)
- âœ… Melhor performance

**Passos:**

1. **Instalar Fly CLI:**
```bash
curl -L https://fly.io/install.sh | sh
```

2. **Login:**
```bash
fly auth login
```

3. **Inicializar app:**
```bash
fly launch
# Escolha:
# - Nome: stock-prediction-api
# - Region: SÃ£o Paulo (gru) ou mais prÃ³ximo
# - Skip PostgreSQL
```

4. **Deploy:**
```bash
fly deploy
```

5. **Abrir app:**
```bash
fly open
```

**Comandos Ãºteis:**
```bash
fly logs          # Ver logs
fly status        # Status da app
fly scale count 1 # Escalar para 1 instÃ¢ncia
```

---

### **4. Heroku (Legacy)**

**CaracterÃ­sticas:**
- âš ï¸ NÃ£o tem mais free tier
- âš ï¸ MÃ­nimo $7/mÃªs
- âœ… FÃ¡cil de usar

**Passos:**

1. **Instalar Heroku CLI:**
```bash
brew install heroku/brew/heroku
```

2. **Login:**
```bash
heroku login
```

3. **Criar app:**
```bash
heroku create stock-prediction-api
heroku stack:set container  # Usar Docker
```

4. **Deploy:**
```bash
git push heroku main
```

5. **Abrir:**
```bash
heroku open
```

**LimitaÃ§Ãµes:**
- MÃ­nimo $7/mÃªs (Eco Dyno)
- Dorme apÃ³s 30 min de inatividade

---

## ðŸ–¥ï¸ Deploy em VPS (Digital Ocean, AWS EC2, etc.)

### **Requisitos do Servidor:**
- Ubuntu 20.04+ ou Debian 11+
- 1GB RAM mÃ­nimo (2GB recomendado)
- 10GB disco
- Docker instalado

### **Passos:**

1. **Conectar via SSH:**
```bash
ssh user@seu-servidor.com
```

2. **Instalar Docker:**
```bash
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
```

3. **Clonar repositÃ³rio:**
```bash
git clone https://github.com/adriannylelis/stock-prediction-lstm-api.git
cd stock-prediction-lstm-api
```

4. **Build e Run:**
```bash
sudo docker build -t stock-api .
sudo docker run -d \
  --name stock-api \
  -p 80:5001 \
  --restart unless-stopped \
  stock-api
```

5. **Configurar Nginx (opcional):**
```nginx
server {
    listen 80;
    server_name seu-dominio.com;

    location / {
        proxy_pass http://localhost:5001;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

---

## ðŸ”’ VariÃ¡veis de Ambiente

A API nÃ£o requer variÃ¡veis de ambiente para funcionar. Tudo Ã© configurado via arquivos:

- Modelo: `artifacts/model_lstm_1x16.pt`
- Scaler: `artifacts/scaler_corrected.pkl`
- Config: `artifacts/model_config.json`

**Opcional (para produÃ§Ã£o):**
```bash
# Se quiser desabilitar debug mode
export FLASK_ENV=production

# Custom port (padrÃ£o: 5001)
export PORT=8080
```

---

## ðŸ“Š Monitoramento

### **Healthcheck Endpoint**

```bash
# Verificar se API estÃ¡ UP
curl https://sua-api.com/health

# Response esperado:
{
  "status": "healthy",
  "timestamp": "2025-12-30T...",
  "service": "stock-prediction-lstm-api"
}
```

### **Logs**

**Docker:**
```bash
docker logs -f stock-api
```

**Railway/Render:**
- Logs disponÃ­veis no dashboard

**Fly.io:**
```bash
fly logs
```

---

## ðŸ§ª Testar Deployment

ApÃ³s fazer deploy, teste todos os endpoints:

```bash
# Substitua YOUR_URL pela URL do seu deploy
BASE_URL="https://stock-prediction-api.onrender.com"

# 1. Health check
curl $BASE_URL/health

# 2. Model info
curl $BASE_URL/model/info

# 3. Prediction
curl -X POST $BASE_URL/predict \
  -H "Content-Type: application/json" \
  -d '{"ticker": "AAPL"}'
```

---

## âš ï¸ Troubleshooting

### **Problema: Container nÃ£o inicia**

**SoluÃ§Ã£o:**
```bash
# Ver logs do container
docker logs stock-api

# Verificar se porta estÃ¡ livre
lsof -i :5001

# Rebuild forÃ§ado
docker build --no-cache -t stock-api .
```

### **Problema: NumPy version error**

**SoluÃ§Ã£o:**
- Verificar se Dockerfile instala `numpy<2.0`
- Rebuild da imagem

### **Problema: Out of Memory**

**SoluÃ§Ã£o:**
- Aumentar RAM do servidor (mÃ­nimo 1GB)
- Usar apenas 1 worker do Flask

### **Problema: API lenta (cold start)**

**SoluÃ§Ã£o:**
- Usar health check para manter container aquecido
- Configurar keep-alive:
```bash
# Criar cronjob que pinga /health a cada 10 min
*/10 * * * * curl https://sua-api.com/health
```

---

## ðŸ“ž Suporte

- **Issues:** [GitHub Issues](https://github.com/adriannylelis/stock-prediction-lstm-api/issues)
- **DocumentaÃ§Ã£o:** [README.md](../README.md)
- **Plano de ImplementaÃ§Ã£o:** [PLANO_PESSOA_B.md](PLANO_PESSOA_B.md)

---

## ðŸŽ¯ RecomendaÃ§Ã£o Final

Para produÃ§Ã£o, recomendamos:

1. **Hobby/Teste:** Render.com (free tier)
2. **ProduÃ§Ã£o leve:** Railway.app ($5/mÃªs)
3. **ProduÃ§Ã£o pesada:** Fly.io ou VPS com Docker
4. **Enterprise:** AWS ECS/EKS com Fargate

---

**Ãšltima atualizaÃ§Ã£o:** Dezembro 2025
