# üìä Relat√≥rio de Decis√µes T√©cnicas - LSTM Stock Prediction

**Projeto:** API de Previs√£o de Pre√ßos de A√ß√µes com LSTM  
**Dataset:** PETR4.SA (Petrobras) - 1484 registros (2020-2025)  
**Data:** Dezembro 2025  
**Autor:** Pessoa A (Data Science)

---

## üéØ Objetivo

Desenvolver um modelo LSTM para previs√£o de pre√ßos de a√ß√µes da Petrobras (PETR4.SA) com horizonte de 1 dia, avaliando diferentes arquiteturas e validando a superioridade do modelo sobre baselines simples.

---

## üîç Descobertas Cr√≠ticas

### ‚ö†Ô∏è Data Leakage Identificado e Corrigido

**Problema:** Durante an√°lise profunda do notebook, identificamos que o scaler estava sendo ajustado no dataset completo (incluindo dados de teste), causando vazamento de informa√ß√£o do futuro para o passado.

```python
# ‚ùå ERRADO (data leakage)
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)  # Ajusta em TODO o dataset
# Depois faz split train/val/test

# ‚úÖ CORRETO
scaler_corrected = MinMaxScaler()
scaler_corrected.fit(train_data_raw)  # Ajusta APENAS no treino
train_scaled = scaler_corrected.transform(train_data_raw)
val_scaled = scaler_corrected.transform(val_data_raw)
test_scaled = scaler_corrected.transform(test_data_raw)
```

**Impacto:** Ap√≥s corre√ß√£o, as m√©tricas revelaram a real dificuldade do problema. O modelo LSTM passou a ter performance marginal sobre baseline naive.

**A√ß√£o Tomada:** Criamos `scaler_corrected.pkl` que deve ser usado em produ√ß√£o. O scaler original foi mantido apenas para fins de compara√ß√£o hist√≥rica.

---

## üèóÔ∏è Arquiteturas Testadas

Treinamos 6 variantes de LSTM por **300 epochs** cada (com early stopping patience=50):

| Arquitetura | Params | Train Loss | Val Loss | Test MAPE | Params/Samples |
|-------------|--------|-----------|----------|-----------|----------------|
| **LSTM-1x16** ‚≠ê | 1,233 | 0.000193 | 0.000271 | **1.21%** | 1.24:1 |
| LSTM-1x32 | 4,513 | 0.000150 | 0.000264 | 1.22% | 4.5:1 |
| LSTM-2x50 | 31,051 | 0.000085 | 0.000454 | 2.04% | 31:1 |
| LSTM-1x64 | 17,217 | 0.000107 | 0.000365 | 1.57% | 17:1 |
| LSTM-1x32+L2 | 4,513 | 0.000489 | 0.000548 | 2.56% | 4.5:1 |
| LSTM-1x32 LR alto | 4,513 | 0.000661 | 0.001131 | 4.21% | 4.5:1 |

**Baselines para Compara√ß√£o:**
- **Naive (t-1 ‚Üí t):** MAPE 1.06% ‚≠ê Extremamente competitivo
- **MA-5:** MAPE 1.82%
- **MA-20:** MAPE 3.25%

---

## üéì Decis√µes Arquiteturais

### 1. Escolha do Modelo: LSTM-1x16

**Justificativa:**
- ‚úÖ **Melhor balance complexidade/performance:** 1,233 par√¢metros vs 31K da arquitetura 2x50
- ‚úÖ **Generaliza√ß√£o superior:** MAPE 1.21% vs 2.04% do modelo mais complexo
- ‚úÖ **Ratio params/samples saud√°vel:** 1.24:1 (vs 31:1 que indica overfitting potencial)
- ‚úÖ **Converg√™ncia est√°vel:** Train loss 0.000193, Val loss 0.000271, gap 0.000077
- ‚úÖ **Melhora sobre naive:** 14.5% (1.21% vs 1.06%)

**Configura√ß√£o Final:**
```python
StockLSTM(
    input_size=1,        # Univariado (Close price)
    hidden_size=16,      # 16 unidades ocultas
    num_layers=1,        # 1 camada LSTM
    dropout=0.0,         # Sem dropout (dataset pequeno)
    output_size=1
)
```

**Hiperpar√¢metros:**
- Learning Rate: 0.001 (Adam)
- Batch Size: 32
- Weight Decay: 1e-5 (regulariza√ß√£o L2 leve)
- Loss Function: MSE
- Early Stopping: Patience 50

### 2. Escolha de Features: Univariado

**Decis√£o:** Usar apenas `Close` price ao inv√©s de 20 features (5 OHLCV + 15 indicadores t√©cnicos).

**Justificativa:**
- ‚úÖ Menor risco de overfitting com dataset pequeno (996 amostras treino)
- ‚úÖ Simplicidade e interpretabilidade
- ‚úÖ Testes preliminares n√£o mostraram ganho significativo com features adicionais
- ‚úÖ Reduz dimensionalidade e tempo de treinamento

### 3. Lookback Window: 60 dias

**Decis√£o:** Sequ√™ncias de 60 dias para prever pr√≥ximo dia.

**Justificativa:**
- ‚úÖ ~3 meses de hist√≥rico captura sazonalidade mensal
- ‚úÖ Balance entre contexto suficiente e tamanho do dataset
- ‚úÖ Padr√£o comum na literatura de forecasting financeiro

### 4. Split Temporal: 70/15/15

**Decis√£o:** 
- Train: 70% (996 sequ√™ncias)
- Validation: 15% (213 sequ√™ncias)
- Test: 15% (215 sequ√™ncias)

**Justificativa:**
- ‚úÖ Split temporal preserva ordem cronol√≥gica (critical para s√©ries temporais)
- ‚úÖ Valida√ß√£o permite early stopping sem contaminar teste
- ‚úÖ Propor√ß√µes balanceadas para dataset de tamanho m√©dio

---

## üìà Metodologia de Avalia√ß√£o

### M√©tricas Utilizadas

1. **MAE (Mean Absolute Error):** Erro m√©dio em R$
2. **RMSE (Root Mean Squared Error):** Penaliza erros grandes
3. **MAPE (Mean Absolute Percentage Error):** Erro percentual m√©dio (m√©trica principal)
4. **R¬≤ Score:** Coeficiente de determina√ß√£o

### Valida√ß√£o Cruzada Walk-Forward

Implementamos valida√ß√£o walk-forward com 5 splits para avaliar generaliza√ß√£o temporal:

```
Split 1: Train [0:60%]  ‚Üí Test [60%:72%]
Split 2: Train [0:65%]  ‚Üí Test [65%:77%]
Split 3: Train [0:70%]  ‚Üí Test [70%:82%]
Split 4: Train [0:75%]  ‚Üí Test [75%:87%]
Split 5: Train [0:80%]  ‚Üí Test [80%:92%]
```

**Resultado LSTM-1x16 (Walk-Forward):**
- MAPE M√©dio: **43.15% ¬± 6.24%** üò±
- Range: 37.11% - 54.88%

**Interpreta√ß√£o:** O modelo **n√£o generaliza bem** para mudan√ßas de regime. Performance no split √∫nico (1.21%) √© otimista. Em produ√ß√£o, espera-se performance degradada em per√≠odos de alta volatilidade ou mudan√ßas estruturais no mercado.

---

## üöÄ Configura√ß√£o de Hardware

### GPU Utilizada

- **Modelo:** NVIDIA GeForce RTX 4050 Laptop GPU
- **VRAM:** 6GB
- **CUDA Version:** 12.6
- **PyTorch:** 2.9.1+cu126

**Speedup:** Treinamento ~10-50x mais r√°pido que CPU (300 epochs em ~7 segundos por arquitetura).

**Valida√ß√£o:**
```python
torch.cuda.is_available()  # True
torch.cuda.get_device_name(0)  # 'NVIDIA GeForce RTX 4050 Laptop GPU'
```

---

## üìä An√°lise de Resultados

### Curvas de Treinamento (LSTM-1x16)

- **Converg√™ncia r√°pida:** Loss cai significativamente nos primeiros 50 epochs
- **Estabilidade:** Loss se estabiliza ap√≥s epoch 100
- **Sem overfitting:** Gap train-val pequeno (0.000077)
- **Best Epoch:** 300 (modelo treinou at√© o fim sem early stopping)

### Distribui√ß√£o de Erros

**LSTM-1x16:**
- Erro m√©dio: R$ 0.06
- Desvio padr√£o: R$ 0.52
- Range: [-R$ 1.84, R$ 1.34]
- Distribui√ß√£o: **N√£o-normal** (Shapiro-Wilk p < 0.05)

**Naive Baseline:**
- Erro m√©dio: -R$ 0.01 (melhor centraliza√ß√£o)
- Desvio padr√£o: R$ 0.47 (menor dispers√£o)
- Range: [-R$ 1.96, R$ 1.20]
- Distribui√ß√£o: **N√£o-normal** (Shapiro-Wilk p < 0.05)

### R¬≤ Score Comparison

- **LSTM-1x16:** R¬≤ = 0.90
- **Naive:** R¬≤ = 0.92 üò±

**Conclus√£o:** Em termos de R¬≤, o baseline naive √© **superior** ao LSTM para este problema espec√≠fico (PETR4 univariado, horizonte 1 dia), mas o naive n√£o aprende o comportamento temporal, como uma LSTM.

---

## üéØ Li√ß√µes Aprendidas

### 1. Data Leakage √© Sutil e Perigoso

O scaler ajustado no dataset completo causava vazamento invis√≠vel nos dados. **Sempre** ajustar transforma√ß√µes apenas no conjunto de treino.

### 2. Simples Frequentemente Vence Complexo

A arquitetura 1x16 (1,2K params) superou 2x50 (31K params). Em ML, complexidade n√£o garante performance.

### 3. Baselines S√£o Essenciais

Sem comparar com naive, ter√≠amos considerado MAPE 1.21% como "excelente". O naive com 1.06% revelou a marginalidade da melhora.

### 4. Valida√ß√£o √önica √© Otimista

Split √∫nico mostrou MAPE 1.21%. Walk-forward revelou 43.15%. **Sempre** usar valida√ß√£o temporal em s√©ries temporais.

### 5. GPU Acelera Experimenta√ß√£o

Com RTX 4050, testamos 6 arquiteturas √ó 300 epochs em ~45 segundos total. Sem GPU, levaria 15-30 minutos.

### 6. Problemas Financeiros S√£o Dif√≠ceis

Previs√£o de pre√ßos de a√ß√µes com horizonte 1 dia e features simples √© **extremamente dif√≠cil**. LSTM n√£o √© "bala de prata".

---

## üîÆ Recomenda√ß√µes para Produ√ß√£o

### Expectativas Realistas

1. **Performance Esperada:** MAPE entre 1.2% - 5% em per√≠odos normais
2. **Degrada√ß√£o em Crises:** Esperar MAPE 10-50% em mudan√ßas de regime (ex: crises, an√∫ncios)
3. **Compara√ß√£o Cont√≠nua:** Monitorar se LSTM continua superando naive baseline

### Monitoramento Necess√°rio

- **Drift Detection:** Comparar distribui√ß√£o de erros ao longo do tempo
- **Baseline Tracking:** Avaliar continuamente se LSTM > Naive
- **Retreino Peri√≥dico:** Retreinar modelo mensalmente com dados recentes

### Melhorias Futuras

1. **Features Externas:**
   - Pre√ßo do petr√≥leo (Brent)
   - Sentimento de not√≠cias (NLP)
   - Indicadores macroecon√¥micos

2. **Arquiteturas Alternativas:**
   - Transformer (attention mechanism)
   - Ensemble LSTM + XGBoost
   - GRU (menos par√¢metros que LSTM)

3. **Horizontes Alternativos:**
   - Previs√£o 3-5 dias pode ter melhor signal/noise ratio
   - Previs√£o de faixa (min/max) ao inv√©s de ponto

---

## üì¶ Artefatos Salvos

### Arquivos Produzidos

```
artifacts/
‚îú‚îÄ‚îÄ model_lstm_1x16.pt          # Modelo PyTorch treinado (1,233 params)
‚îú‚îÄ‚îÄ scaler_corrected.pkl         # MinMaxScaler SEM data leakage ‚ö†Ô∏è
‚îú‚îÄ‚îÄ model_config.json            # Configura√ß√£o completa + m√©tricas
‚îî‚îÄ‚îÄ test_predictions.json        # 215 predi√ß√µes do conjunto de teste
```

### Uso em Produ√ß√£o

```python
import torch
import pickle
import json

# Carregar modelo
model = StockLSTM(input_size=1, hidden_size=16, num_layers=1)
model.load_state_dict(torch.load('artifacts/model_lstm_1x16.pt'))
model.eval()

# Carregar scaler CORRETO (critical!)
with open('artifacts/scaler_corrected.pkl', 'rb') as f:
    scaler = pickle.load(f)

# Infer√™ncia
# 1. Normalizar √∫ltimos 60 dias com scaler
# 2. Criar tensor [1, 60, 1]
# 3. Passar pelo modelo
# 4. Desnormalizar predi√ß√£o
```

**‚ö†Ô∏è CR√çTICO:** Usar `scaler_corrected.pkl` em produ√ß√£o. O scaler sem sufixo tem data leakage!

---

## üìã Configura√ß√£o Reproduz√≠vel

### Ambiente

```yaml
python: 3.11+
pytorch: 2.9.1+cu126
numpy: 1.26.4
pandas: 2.2.0
scikit-learn: 1.4.0
yfinance: 0.2.48
matplotlib: 3.8.2
```

### Seeds Fixados

```python
SEED = 42
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
np.random.seed(SEED)
random.seed(SEED)
torch.backends.cudnn.deterministic = True
```

---

## ‚úÖ Conclus√£o

### Decis√£o Final

**Modelo Selecionado:** LSTM-1x16 (1 camada, 16 unidades ocultas)

**Justificativa:**
- ‚úÖ Simplicidade e efici√™ncia computacional
- ‚úÖ Melhor generaliza√ß√£o entre arquiteturas testadas
- ‚úÖ Melhora 14.5% sobre naive baseline
- ‚úÖ Converg√™ncia est√°vel sem overfitting
- ‚úÖ Ratio params/samples saud√°vel (1.24:1)

### Limita√ß√µes Reconhecidas

- ‚ùå Melhora marginal sobre naive (1.21% vs 1.06%)
- ‚ùå Performance degrada em walk-forward (43% MAPE)
- ‚ùå R¬≤ inferior ao baseline naive (0.90 vs 0.92)
- ‚ùå Distribui√ß√£o de erros n√£o-normal

### Recomenda√ß√£o

O modelo LSTM-1x16 est√° **pronto para produ√ß√£o** com as seguintes ressalvas:

1. **N√£o √© silver bullet:** Melhora marginal sobre naive
2. **Monitoramento cr√≠tico:** Comparar continuamente com baseline
3. **Retreino frequente:** Mensal ou quando performance degrada
4. **Expectativas realistas:** MAPE 1-5% em condi√ß√µes normais, 10-50% em crises

---

**Documento Gerado:** 15/12/2025  
**Respons√°vel:** Pessoa A (Data Science)  
**Pr√≥ximos Passos:** Handover para Pessoa B (Engenharia) para desenvolvimento da API
